{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 4 0 0 0 0 0 0 1 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 5 0 5 5 5 5 5 5]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0 2 1 2 2 2 2 2 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 5 5 5 5 5 5 5 5]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "root_dir = os.path.abspath('.')\n",
    "data_dir = os.path.join(root_dir, 'dataset')\n",
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "test_x, _ = utils.featurize(test, stage='test')\n",
    "\n",
    "\n",
    "train_x, train_y = utils.featurize(train)\n",
    "print(test_x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba(clf,x):\n",
    "    a = []\n",
    "    for v in clf.predict_proba(x.reshape(1,-1)):\n",
    "        a.append([v[0,1]])\n",
    "       \n",
    "    return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n",
    "cv_results = cross_validate(tree,train_x,train_y,cv=5,return_estimator=True,return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90202099 0.90524535 0.90646738 0.90477533 0.90606004]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_score'])\n",
    "clf=cv_results[\"estimator\"][0]\n",
    "\n",
    "# print(np.shape(clf.predict_proba(train_x[6].reshape(1, -1))))\n",
    "# clf.predict_proba(train_x[6].reshape(1, -1))[3][0][1]\n",
    "f = open(\"decision_tree.csv\",\"w\")\n",
    "k = 0\n",
    "for feat in test_x:\n",
    "    prob = get_proba(clf,feat)\n",
    "    f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x[0]) for x in prob))\n",
    "    f.write(\"\\n\")\n",
    "    k+=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90484098 0.90631071 0.90928746 0.90743874 0.90750141]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf_cv_results=cross_validate(rf,train_x,train_y,cv=5,return_estimator=True,return_train_score=False)\n",
    "print(rf_cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf_cv_results['estimator'][0]\n",
    "k=0\n",
    "ran_f = open(\"random_forest.csv\",\"w\")\n",
    "for feat in test_x:\n",
    "    prob = get_proba(rf_clf,feat)\n",
    "    ran_f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x[0]) for x in prob))\n",
    "    ran_f.write(\"\\n\")\n",
    "    k+=1\n",
    "ran_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93990287 0.94018487 0.94077834 0.93996365 0.9398991 ]\n",
      "[0.99006737 0.99050573 0.98972238 0.99016106 0.99041173]\n",
      "[0.96371612 0.96343412 0.96374632 0.96506236 0.96289913]\n",
      "[0.99696068 0.99696068 0.99689801 0.99699182 0.99699182]\n",
      "[0.95484882 0.95710481 0.95757348 0.95431472 0.95456397]\n",
      "[0.99128936 0.99122642 0.99113242 0.99106975 0.99122642]\n"
     ]
    }
   ],
   "source": [
    "lr = []\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr_cv_results = []\n",
    "i=0\n",
    "while(i<6):\n",
    "    \n",
    "    lr_cv_result = cross_validate(lr[i],train_x,column(train_y,i),cv=5,return_estimator=True,return_train_score=False)\n",
    "    print(lr_cv_result['test_score'])\n",
    "    lr_cv_results.append(lr_cv_result)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_get_proba(clf,x):\n",
    "    a = []\n",
    "    for i in clf:\n",
    "        \n",
    "        for v in i.predict_proba(x.reshape(1,-1)):\n",
    "            a.append(v[1])\n",
    "       \n",
    "    return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.06196153295436414,0.010201813287534878,0.03273787179065023,0.004423638436312418,0.04763677331523011,0.01071707247351741'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clfs = []\n",
    "lr_clfs.append(lr_cv_results[0]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[1]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[2]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[3]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[4]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[5]['estimator'][0])\n",
    "\n",
    "\",\".join(str(x) for x in lr_get_proba(lr_clfs,test_x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "lr_f = open(\"logistic_regression.csv\",\"w\")\n",
    "for feat in test_x:\n",
    "    prob = lr_get_proba(lr_clfs,feat)\n",
    "    lr_f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x) for x in prob))\n",
    "    lr_f.write(\"\\n\")\n",
    "    k+=1\n",
    "lr_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = []\n",
    "svc.append(svm.SVC())\n",
    "svc.append(svm.SVC())\n",
    "svc.append(svm.SVC())\n",
    "svc.append(svm.SVC())\n",
    "svc.append(svm.SVC())\n",
    "svc.append(svm.SVC())\n",
    "svc_cv_results = []\n",
    "j=0\n",
    "while(j<6):\n",
    "    svc_cv_result = cross_validate(svc[j],train_x,column(train_y,j),cv=5,return_estimator=True,return_train_score=False)\n",
    "    print(svc_cv_results['test_score'])\n",
    "    svc_cv_results.append(svc_cv_results)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when ready, set this to the best model you found, trained on the test data:\n",
    "best_classifier = None\n",
    "\n",
    "with open('classifier.pickle', 'wb') as f: # 'wb' stands for 'write bytes'\n",
    "    pickle.dump(best_classifier, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
