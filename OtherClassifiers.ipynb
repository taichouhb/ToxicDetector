{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.01388889 0.         0.\n",
      "  0.05555556 0.05555556 0.         0.         0.01388889 0.\n",
      "  0.         0.         0.01388889 0.         0.         0.\n",
      "  0.02777778 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.53846154 0.         0.         0.         0.07692308 0.\n",
      "  0.15384615 0.         0.07692308 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.25       0.3125     0.         0.         0.         0.\n",
      "  0.25       0.3125     0.         0.3125     0.3125     0.3125\n",
      "  0.3125     0.3125     0.3125    ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.10526316 0.         0.         0.         0.02631579 0.\n",
      "  0.         0.         0.15789474 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14285714 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.16129032 0.06451613 0.         0.         0.03225806 0.\n",
      "  0.         0.06451613 0.03225806 0.06451613 0.06451613 0.06451613\n",
      "  0.06451613 0.06451613 0.06451613]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.16666667 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.3853211  0.04587156 0.         0.         0.00917431 0.\n",
      "  0.09174312 0.04587156 0.04587156 0.04587156 0.04587156 0.04587156\n",
      "  0.04587156 0.04587156 0.04587156]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.17073171 0.         0.         0.         0.12195122 0.\n",
      "  0.04878049 0.         0.07317073 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "root_dir = os.path.abspath('.')\n",
    "data_dir = os.path.join(root_dir, 'dataset')\n",
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "test_x, _ = utils.featurize(test, stage='test')\n",
    "\n",
    "\n",
    "train_x, train_y = utils.featurize(train)\n",
    "print(test_x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba(clf,x):\n",
    "    a = []\n",
    "    for v in clf.predict_proba(x.reshape(1,-1)):\n",
    "        a.append([v[0,1]])\n",
    "       \n",
    "    return a\n",
    "\n",
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905979162568257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n",
    "cv_results = cross_validate(tree,train_x,train_y,cv=5,return_estimator=True,return_train_score=False)\n",
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90202099 0.90524535 0.90646738 0.90477533 0.90606004]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_score'])\n",
    "clf=cv_results[\"estimator\"][0]\n",
    "\n",
    "# print(np.shape(clf.predict_proba(train_x[6].reshape(1, -1))))\n",
    "# clf.predict_proba(train_x[6].reshape(1, -1))[3][0][1]\n",
    "f = open(\"decision_tree.csv\",\"w\")\n",
    "k = 0\n",
    "for feat in test_x:\n",
    "    prob = get_proba(clf,feat)\n",
    "    f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x[0]) for x in prob))\n",
    "    f.write(\"\\n\")\n",
    "    k+=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15294,  1595,  8449,   478,  7877,  1405])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_y,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90722231 0.90919346 0.91063483 0.91082284 0.91029015]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=4)\n",
    "rf_cv_results=cross_validate(rf,train_x,train_y,cv=5,return_estimator=True,return_train_score=False)\n",
    "print(rf_cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32326269 0.32517514 0.32870057 0.32513946 0.32769304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=4)\n",
    "rf_cv_results=cross_validate(rf,train_x,train_y,cv=5,scoring='f1_macro',return_estimator=True,return_train_score=False)\n",
    "print(rf_cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['score_time', 'estimator', 'fit_time', 'test_score'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9097956533288963"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plot_learning_curve(rf,\"random forest learning curve\",train_x,train_y)\n",
    "plt.show()\n",
    "np.mean(rf_cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 1 1 0 1 0]\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "[0.    0.    0.    0.    0.    0.    4.625 0.25  0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "[0.   0.   0.   0.   0.   0.   0.86 0.   0.   0.   0.02 0.   0.08 0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "[0.  0.  0.  0.  0.  0.  0.3 0.  0.2 0.  0.1 0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0. ]\n",
      "predicted: [[1 0 0 0 0 0]]\n",
      "expected: [1 0 1 0 1 1]\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.1981982  0.00900901 0.06306306 0.         0.06306306 0.\n",
      " 0.12612613 0.         0.05405405 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "I'm Sorry \n",
      "\n",
      "I'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82\n",
      "[0.         0.         0.         0.01612903 0.         0.\n",
      " 0.16129032 0.09677419 0.         0.         0.01612903 0.\n",
      " 0.03225806 0.11290323 0.03225806 0.09677419 0.09677419 0.09677419\n",
      " 0.09677419 0.09677419 0.09677419]\n",
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 0 1 0 0 0]\n",
      "GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 3.2962963  0.22222222 0.03703704 0.         0.         0.\n",
      " 0.         0.07407407 0.         0.07407407 0.07407407 0.07407407\n",
      " 0.07407407 0.07407407 0.07407407]\n",
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 1 1 0 1 0]\n",
      "Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!\n",
      "[0.         0.         0.15789474 0.         0.         0.\n",
      " 0.05263158 0.26315789 0.05263158 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "Why can't you believe how fat Artie is? Did you see him on his recent appearence on the Tonight Show with Jay Leno? He looks absolutely AWFUL! If I had to put money on it, I'd say that Artie Lange is a can't miss candidate for the 2007 Dead pool!   \n",
      "\n",
      "  \n",
      "Kindly keep your malicious fingers off of my above comment, . Everytime you remove it, I will repost it!!!\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.30136986 0.05479452 0.06849315 0.         0.04109589 0.\n",
      " 0.04109589 0.05479452 0.02739726 0.05479452 0.05479452 0.05479452\n",
      " 0.05479452 0.05479452 0.05479452]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 1 0 1 0]\n",
      "All of my edits are good.  Cunts like you who revert good edits because you're too stupid to understand how to write well , and then revert other edits just because you've decided to bear a playground grudge, are the problem.  Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.05172414 0.06896552 0.         0.         0.03448276 0.\n",
      " 0.         0.06896552 0.05172414 0.06896552 0.06896552 0.06896552\n",
      " 0.06896552 0.06896552 0.06896552]\n",
      "predicted: [[1 0 0 0 0 0]]\n",
      "expected: [0 0 0 0 0 0]\n",
      "That's what I'm looking through, it looks like he was just being an all around dick on talk pages though. It's nothing too bad though, looks more like an inability to express himself properly. Thank you for your concern also, Cheers!! -\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.11904762 0.02380952 0.04761905 0.         0.07142857 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 1 0 0]\n",
      "Hi! I am back again!\n",
      "Last warning!\n",
      "Stop undoing my edits or die!\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.36363636 0.         0.36363636 0.         0.         0.\n",
      " 0.18181818 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 1 0]\n",
      "Would you both shut up, you don't run wikipedia, especially a stupid kid.\n",
      "[0.         0.         0.07692308 0.         0.         0.\n",
      " 0.07692308 0.         0.         0.         0.15384615 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 1 0 1 1]\n",
      "A pair of jew-hating weiner nazi schmucks.\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.14285714 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.14285714 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "\"\n",
      "\n",
      "SORRY PUCK BUT NO ONE EVER SAID DICK WAS NUMBER ONE!! But he is clearly listed as being \"\"second only to Batman\"\" and a \"\"master detective and martial artist\"\" and been trained in all the mentioned combat discplines. No need to mention in skills/abilities about the battles he's lost and won because thats not what an encylopia is supposed to do. \n",
      "\n",
      "Also, what your problem is your going by low end showings and not HIGH end showings where he's proven more than a match for a meta like Slade and pinned Shiva down in one of his earliest appearences.\n",
      " \"\n",
      "[0.   0.   0.   0.   0.   0.   0.51 0.03 0.02 0.   0.01 0.   0.05 0.03\n",
      " 0.04 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "\"\n",
      "\n",
      "UNBLOCK ME OR I'LL GET MY LAWYERS ON TO YOU FOR BLOCKING MY CONSTITUTIONAL RIGHT TO FREE SPEECH\"\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 4.27777778 0.         0.         0.         0.         0.\n",
      " 0.11111111 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 1 0]\n",
      "You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.07407407 0.         0.         0.         0.03703704 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[1 0 0 0 0 0]]\n",
      "expected: [1 0 1 1 1 1]\n",
      "I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms\n",
      "[0.         0.         0.03448276 0.         0.         0.\n",
      " 0.13793103 0.03448276 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [0 0 0 0 1 0]\n",
      "REPLY ABOVE:\n",
      "That was me, loser. The UN defines Vietnam to be part of Southeast Asia. And far as I know Vietnam is part of ASEAN, and used to be part of French Indochina with Laos and all those shit countries Anyway your culture has always been more influenced by SEA than Han Chinese (as in proper Yangtze Han Chinese, not the fringe indigenous tribes in Guangzhou/Guangxi). \n",
      "\n",
      "Just admit that you vietnamese are all a bunch of wannabe crap people. ALL the east asian people I've spoken to thinks of Vietnam as a very integral part of SEA, and we all think you're backward, dirty and speak in a horrible swearing language. Doesn't matter what crap you spout on Wikipedia, won't change the way people in the real world think.\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.3875969  0.00775194 0.         0.         0.04651163 0.\n",
      " 0.02325581 0.         0.03875969 0.         0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 1 1 0 1 0]\n",
      "you are a stupid fuck \n",
      "\n",
      "and your mother's cunt stinks\n",
      "[0.  0.1 0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.1 0.  0. ]\n",
      "predicted: [[1 0 1 0 0 0]]\n",
      "expected: [1 0 1 0 1 1]\n",
      "Kill all niggers. \n",
      "\n",
      "I have hard, that others have said this.. should this be included? That racists sometimes say these.\n",
      "[0.   0.   0.   0.   0.   0.   0.15 0.05 0.   0.   0.05 0.   0.1  0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "predicted: [[1 0 0 0 0 0]]\n",
      "expected: [0 0 0 0 0 0]\n",
      "Well I will use my user page then, don't tell meyour gonna remove it too, because that will piss me off and drive me nuts. Also I am not making a personal ttack on Jimmy wales, I am saying he is a bit to greedy dont you think? He's got 6 million dollars already and now he's asking for more.\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.11666667 0.01666667 0.         0.         0.05       0.\n",
      " 0.         0.01666667 0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 0 1 0 1 1]\n",
      "u r a tw@ fuck off u gay boy.U r smelly.Fuck ur mum poopie\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.14285714 0.07142857 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "Atheism is full of bias shit\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.16666667 0.16666667 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[0 0 0 0 0 0]]\n",
      "expected: [1 0 0 0 0 0]\n",
      "Hey why you are spreading misconceptions and trying to spread false information to the people.You not even know who won the battle and who lost.you are the cheapest person on the earth.Bloody ignorant fool.Check sources before spreading rumors\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.10526316 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.13157895 0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "predicted: [[1 0 1 0 1 0]]\n",
      "expected: [1 0 1 0 0 0]\n",
      "Fuck off\n",
      "\n",
      "You are NOT an administrator. You DON'T have the authority to tell me what to do.\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.58823529 0.05882353 0.         0.         0.         0.\n",
      " 0.11764706 0.         0.05882353 0.         0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = 0\n",
    "count = 0\n",
    "while(count<50):\n",
    "    a = rf_cv_results['estimator'][4].predict(train_x[idx].reshape(1,-1))\n",
    "    if(not (a.astype(int)==train_y[idx]).all()):\n",
    "        print(\"predicted: \",end=\"\")\n",
    "        print(a.astype(int))\n",
    "        print(\"expected: \",end=\"\")\n",
    "        print(train_y[idx])\n",
    "        print(train.values[idx][1])\n",
    "        print(train_x[idx])\n",
    "        count+=1\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_f = RandomForestClassifier()\n",
    "parameters = {'n_estimators':[300,400,500,600,700],'min_samples_leaf': [4, 8, 10],'criterion': ['gini', 'entropy']}\n",
    "rfs = GridSearchCV(ran_f, parameters, cv=5)\n",
    "rfs.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([139.49301476, 183.4048697 , 216.53961377, 254.49498482,\n",
       "        292.28981099, 117.83096762, 157.21645169, 195.81741047,\n",
       "        245.992558  , 270.15040126, 113.42047105, 153.15201044,\n",
       "        188.70641985, 229.07230639, 270.33021464, 159.84373984,\n",
       "        213.80976849, 265.40656219, 316.66983218, 368.71965418,\n",
       "        149.28168707, 199.56126842, 248.52116828, 303.34603605,\n",
       "        372.69907465, 158.71623244, 211.16108875, 261.90978212,\n",
       "        293.78175302, 342.21890721]),\n",
       " 'mean_score_time': array([4.13468742, 5.52610269, 6.81144938, 8.4307889 , 9.59236431,\n",
       "        3.9394989 , 5.24314942, 6.56454639, 7.97624359, 9.19871073,\n",
       "        3.86701045, 5.25098157, 6.44697599, 7.77066789, 9.08452568,\n",
       "        3.98445449, 5.27895036, 6.600809  , 7.98061357, 9.26132555,\n",
       "        3.82501984, 5.12159362, 6.39070044, 7.69368873, 8.95484424,\n",
       "        3.84083858, 5.09334893, 6.4804215 , 7.60905185, 8.84001923]),\n",
       " 'mean_test_score': array([0.9096327 , 0.90964524, 0.9096891 , 0.90957003, 0.90962644,\n",
       "        0.90963897, 0.90969537, 0.9096139 , 0.90967657, 0.90963897,\n",
       "        0.9095199 , 0.90941963, 0.90954497, 0.90952617, 0.9095199 ,\n",
       "        0.90976431, 0.90962017, 0.90981444, 0.90977057, 0.90974551,\n",
       "        0.9095951 , 0.9094071 , 0.90951363, 0.90946977, 0.90956377,\n",
       "        0.90945097, 0.90932563, 0.90935696, 0.90947603, 0.90933816]),\n",
       " 'mean_train_score': array([0.91786258, 0.91788765, 0.91779991, 0.91783125, 0.91787512,\n",
       "        0.91338809, 0.91333638, 0.91336302, 0.91333012, 0.91329722,\n",
       "        0.9125076 , 0.9125452 , 0.9125781 , 0.91250133, 0.91252013,\n",
       "        0.91774351, 0.91777485, 0.91779991, 0.91776231, 0.91775448,\n",
       "        0.91325022, 0.91320478, 0.91318755, 0.91329565, 0.91329565,\n",
       "        0.9123431 , 0.912376  , 0.91241203, 0.91241673, 0.91235093]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 4, 4,\n",
       "                    4, 4, 4, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[300, 400, 500, 600, 700, 300, 400, 500, 600, 700, 300,\n",
       "                    400, 500, 600, 700, 300, 400, 500, 600, 700, 300, 400,\n",
       "                    500, 600, 700, 300, 400, 500, 600, 700],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'min_samples_leaf': 4, 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 4, 'n_estimators': 400},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 4, 'n_estimators': 500},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 4, 'n_estimators': 600},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 4, 'n_estimators': 700},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 8, 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 8, 'n_estimators': 400},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 8, 'n_estimators': 500},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 8, 'n_estimators': 600},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 8, 'n_estimators': 700},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 10, 'n_estimators': 400},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 10, 'n_estimators': 500},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 10, 'n_estimators': 600},\n",
       "  {'criterion': 'gini', 'min_samples_leaf': 10, 'n_estimators': 700},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 4, 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 4, 'n_estimators': 400},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 4, 'n_estimators': 500},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 4, 'n_estimators': 600},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 4, 'n_estimators': 700},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 8, 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 8, 'n_estimators': 400},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 8, 'n_estimators': 500},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 8, 'n_estimators': 600},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 8, 'n_estimators': 700},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 10, 'n_estimators': 400},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 10, 'n_estimators': 500},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 10, 'n_estimators': 600},\n",
       "  {'criterion': 'entropy', 'min_samples_leaf': 10, 'n_estimators': 700}],\n",
       " 'rank_test_score': array([11,  8,  6, 16, 12,  9,  5, 14,  7,  9, 20, 26, 18, 19, 20,  3, 13,\n",
       "         1,  2,  4, 15, 27, 22, 24, 17, 25, 30, 28, 23, 29], dtype=int32),\n",
       " 'split0_test_score': array([0.90706564, 0.90731631, 0.90703431, 0.90697164, 0.90728498,\n",
       "        0.90737898, 0.90731631, 0.90731631, 0.90750431, 0.90731631,\n",
       "        0.90728498, 0.90690898, 0.90725364, 0.90725364, 0.90728498,\n",
       "        0.90741031, 0.90719098, 0.90744164, 0.90725364, 0.90728498,\n",
       "        0.90712831, 0.90700298, 0.90722231, 0.90712831, 0.90731631,\n",
       "        0.90722231, 0.90694031, 0.90731631, 0.90712831, 0.90734764]),\n",
       " 'split0_train_score': array([0.91842138, 0.91829605, 0.91833521, 0.91835871, 0.91849188,\n",
       "        0.91394842, 0.91378392, 0.91382309, 0.91395626, 0.91388576,\n",
       "        0.91321207, 0.9132199 , 0.91318074, 0.91311023, 0.91309457,\n",
       "        0.91823338, 0.91818638, 0.91835088, 0.91817071, 0.91824121,\n",
       "        0.91380742, 0.91380742, 0.91369775, 0.91387009, 0.91387009,\n",
       "        0.91293006, 0.91299273, 0.9130319 , 0.91303973, 0.91294573]),\n",
       " 'split1_test_score': array([0.90935013, 0.90909945, 0.90919346, 0.90897412, 0.90897412,\n",
       "        0.90919346, 0.90875478, 0.90894278, 0.90897412, 0.90872344,\n",
       "        0.90884878, 0.90897412, 0.90875478, 0.90878611, 0.90875478,\n",
       "        0.90900545, 0.90903679, 0.90906812, 0.90909945, 0.90916212,\n",
       "        0.90900545, 0.90906812, 0.90875478, 0.90903679, 0.90938146,\n",
       "        0.90888012, 0.90900545, 0.90897412, 0.90922479, 0.90888012]),\n",
       " 'split1_train_score': array([0.91786584, 0.91797551, 0.91792068, 0.91788151, 0.91785801,\n",
       "        0.91358092, 0.91340075, 0.91358092, 0.91343209, 0.91340859,\n",
       "        0.91275057, 0.91272707, 0.91281324, 0.91271924, 0.91278191,\n",
       "        0.91794418, 0.91785801, 0.91782668, 0.91794418, 0.91770917,\n",
       "        0.91345559, 0.91342425, 0.91343209, 0.91354176, 0.91355742,\n",
       "        0.9124764 , 0.91257824, 0.91270357, 0.91275057, 0.91260174]),\n",
       " 'split2_test_score': array([0.91029015, 0.91047816, 0.91072883, 0.91044683, 0.91041549,\n",
       "        0.91019615, 0.91013348, 0.91016482, 0.91032149, 0.91025882,\n",
       "        0.91013348, 0.90985148, 0.91035282, 0.91022749, 0.91003948,\n",
       "        0.91072883, 0.91044683, 0.9107915 , 0.91057216, 0.91057216,\n",
       "        0.91072883, 0.91019615, 0.91041549, 0.91029015, 0.91035282,\n",
       "        0.91029015, 0.91050949, 0.91010215, 0.91016482, 0.90994548]),\n",
       " 'split2_train_score': array([0.91780318, 0.91777184, 0.9174585 , 0.91760734, 0.91759167,\n",
       "        0.91315008, 0.91304041, 0.91325192, 0.91324408, 0.91322058,\n",
       "        0.91224923, 0.9122649 , 0.91228056, 0.91216306, 0.91220223,\n",
       "        0.91762301, 0.91761517, 0.91766217, 0.9174585 , 0.91764651,\n",
       "        0.91300125, 0.91299341, 0.91292291, 0.91309525, 0.91293074,\n",
       "        0.91206906, 0.91210823, 0.91207689, 0.91195156, 0.91205339]),\n",
       " 'split3_test_score': array([0.91076017, 0.91076017, 0.9108855 , 0.91085417, 0.91085417,\n",
       "        0.91085417, 0.91148085, 0.91097951, 0.91101084, 0.91113618,\n",
       "        0.91097951, 0.91107351, 0.91082284, 0.91107351, 0.91113618,\n",
       "        0.91113618, 0.91094817, 0.91113618, 0.91094817, 0.91104218,\n",
       "        0.91097951, 0.91076017, 0.91082284, 0.9106035 , 0.9106975 ,\n",
       "        0.9106975 , 0.91013348, 0.91025882, 0.91054083, 0.91044683]),\n",
       " 'split3_train_score': array([0.91754467, 0.91767784, 0.91761517, 0.91769351, 0.91780318,\n",
       "        0.91318142, 0.91326758, 0.91311091, 0.91299341, 0.91299341,\n",
       "        0.9122179 , 0.91218656, 0.9122649 , 0.91210039, 0.91220223,\n",
       "        0.91726266, 0.91763084, 0.91766217, 0.91756034, 0.91758384,\n",
       "        0.91282108, 0.91289941, 0.91283674, 0.91285241, 0.91296991,\n",
       "        0.91196722, 0.91197506, 0.91196722, 0.91202989, 0.91188889]),\n",
       " 'split4_test_score': array([0.9106975 , 0.91057216, 0.9106035 , 0.9106035 , 0.9106035 ,\n",
       "        0.91057216, 0.9107915 , 0.91066617, 0.91057216, 0.91076017,\n",
       "        0.91035282, 0.91029015, 0.91054083, 0.91029015, 0.91038416,\n",
       "        0.91054083, 0.91047816, 0.91063483, 0.91097951, 0.91066617,\n",
       "        0.91013348, 0.91000815, 0.91035282, 0.91029015, 0.91007082,\n",
       "        0.91016482, 0.91003948, 0.91013348, 0.91032149, 0.91007082]),\n",
       " 'split4_train_score': array([0.91767784, 0.91771701, 0.91767001, 0.91761517, 0.91763084,\n",
       "        0.91307958, 0.91318925, 0.91304825, 0.91302475, 0.91297775,\n",
       "        0.91210823, 0.91232757, 0.91235107, 0.91241373, 0.91231973,\n",
       "        0.91765434, 0.91758384, 0.91749767, 0.91767784, 0.91759167,\n",
       "        0.91316575, 0.91289941, 0.91304825, 0.91311875, 0.91315008,\n",
       "        0.91227273, 0.91222573, 0.91228056, 0.9123119 , 0.9122649 ]),\n",
       " 'std_fit_time': array([ 2.9622114 ,  1.38154888, 11.93790799,  2.68365574,  0.8501712 ,\n",
       "         1.07975926,  0.6121706 ,  1.74162209, 16.54879914,  2.08519638,\n",
       "         0.92307433,  1.32745902,  0.80983355,  1.56368405,  1.74863869,\n",
       "         0.83284664,  1.50376288,  2.78606091,  2.13709103,  2.3722143 ,\n",
       "         1.14417298,  2.96571112,  1.14627407, 10.79753458, 19.90626935,\n",
       "         0.70036467,  1.19436908,  2.27512337,  4.31828134,  4.98183635]),\n",
       " 'std_score_time': array([0.04448159, 0.05933732, 0.01632386, 0.36040775, 0.09999189,\n",
       "        0.01771238, 0.01375356, 0.03272868, 0.14955236, 0.05439001,\n",
       "        0.01068735, 0.10750428, 0.0126197 , 0.04721273, 0.06443183,\n",
       "        0.05096119, 0.02123879, 0.02591057, 0.08836739, 0.06871854,\n",
       "        0.01042494, 0.05873377, 0.03357828, 0.07221089, 0.01703265,\n",
       "        0.03331287, 0.03263182, 0.11395279, 0.05252657, 0.02112699]),\n",
       " 'std_test_score': array([0.00137891, 0.00130521, 0.00145892, 0.00145552, 0.00134109,\n",
       "        0.00126208, 0.00149172, 0.00134202, 0.00128145, 0.00142239,\n",
       "        0.001315  , 0.001427  , 0.00135292, 0.00135513, 0.00135718,\n",
       "        0.00138077, 0.00137292, 0.00138289, 0.00143362, 0.00138615,\n",
       "        0.00140888, 0.00131981, 0.00134594, 0.00128852, 0.00120412,\n",
       "        0.00126969, 0.00129276, 0.00112094, 0.00125683, 0.0011231 ]),\n",
       " 'std_train_score': array([0.00030033, 0.0002285 , 0.00030617, 0.00028162, 0.00032431,\n",
       "        0.00033036, 0.00025235, 0.00029466, 0.00035113, 0.00033437,\n",
       "        0.00041605, 0.00038545, 0.00036239, 0.00037446, 0.00035799,\n",
       "        0.00032678, 0.00022759, 0.00029447, 0.0002608 , 0.00024748,\n",
       "        0.00034812, 0.00035848, 0.00032638, 0.0003629 , 0.00036303,\n",
       "        0.00034165, 0.00036778, 0.00039917, 0.00041871, 0.00038108])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5e4fc885f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tree.dot'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-Tpng'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tree.dot'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tree.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-Gdpi=600'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \"\"\"\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = [\"ignore 0\",\"# sexual organ\",\"# violent words\",\"family words\",\"# negative adj\",\"ignored this\",\"# CAPS\",\"# swears\",\"# !\",\"# complimentary words\",\"# commas\",\"None\",\"# newlines\",\"# disability\",\"# racial slurs\",\"# ethics slurs\",\"# archaic\",\"# class\",\"# gender\",\"# religion\",\"# nationality\"]\n",
    "class_names = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "export_graphviz(rfs.best_estimator_[250],out_file='tree.dot',feature_names=feature_names,class_names=class_names, rounded=True,proportion=False,precision=2,filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rfs.best_estimator_#rf_cv_results['estimator'][0]\n",
    "k=0\n",
    "ran_f = open(\"random_forest2.csv\",\"w\")\n",
    "for feat in test_x:\n",
    "    prob = get_proba(rf_clf,feat)\n",
    "    ran_f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x[0]) for x in prob))\n",
    "    ran_f.write(\"\\n\")\n",
    "    k+=1\n",
    "ran_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93990287 0.94018487 0.94077834 0.93996365 0.9398991 ]\n",
      "[0.99006737 0.99050573 0.98972238 0.99016106 0.99041173]\n",
      "[0.96371612 0.96343412 0.96374632 0.96506236 0.96289913]\n",
      "[0.99696068 0.99696068 0.99689801 0.99699182 0.99699182]\n",
      "[0.95484882 0.95710481 0.95757348 0.95431472 0.95456397]\n",
      "[0.99128936 0.99122642 0.99113242 0.99106975 0.99122642]\n"
     ]
    }
   ],
   "source": [
    "lr = []\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr.append(LogisticRegression())\n",
    "lr_cv_results = []\n",
    "i=0\n",
    "while(i<6):\n",
    "    \n",
    "    lr_cv_result = cross_validate(lr[i],train_x,column(train_y,i),cv=5,return_estimator=True,return_train_score=False)\n",
    "    print(lr_cv_result['test_score'])\n",
    "    lr_cv_results.append(lr_cv_result)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97275"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.9399,0.99,0.9637,0.9969,0.9548,0.9912])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_get_proba(clf,x):\n",
    "    a = []\n",
    "    for i in clf:\n",
    "        \n",
    "        for v in i.predict_proba(x.reshape(1,-1)):\n",
    "            a.append(v[1])\n",
    "       \n",
    "    return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.06196153295436414,0.010201813287534878,0.03273787179065023,0.004423638436312418,0.04763677331523011,0.01071707247351741'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clfs = []\n",
    "lr_clfs.append(lr_cv_results[0]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[1]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[2]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[3]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[4]['estimator'][0])\n",
    "lr_clfs.append(lr_cv_results[5]['estimator'][0])\n",
    "\n",
    "\",\".join(str(x) for x in lr_get_proba(lr_clfs,test_x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "lr_f = open(\"logistic_regression.csv\",\"w\")\n",
    "for feat in test_x:\n",
    "    prob = lr_get_proba(lr_clfs,feat)\n",
    "    lr_f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x) for x in prob))\n",
    "    lr_f.write(\"\\n\")\n",
    "    k+=1\n",
    "lr_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94113666 0.94164317 0.94070314]\n",
      "[0.99003591 0.99005471 0.99007314]\n",
      "[0.97283375 0.97407407 0.97382967]\n",
      "[0.99699197 0.99701072 0.99701072]\n",
      "[0.96350886 0.96474968 0.96356389]\n",
      "[0.99133312 0.99133296 0.99142696]\n"
     ]
    }
   ],
   "source": [
    "svc = []\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc.append(svm.SVC(probability=True))\n",
    "svc_cv_results = []\n",
    "j=0\n",
    "while(j<6):\n",
    "    svc_cv_result = cross_validate(svc[j],train_x,column(train_y,j),cv=3,return_estimator=True,return_train_score=False)\n",
    "    print(svc_cv_result['test_score'])\n",
    "    svc_cv_results.append(svc_cv_result)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.9411,0.9900,0.9728,0.9969,0.9635,0.9913])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.054940068937689636,0.009839087747827628,0.019901577256955728,0.0031495311437181855,0.02683736324712405,0.008556809949554831'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clfs = []\n",
    "svc_clfs.append(svc_cv_results[0]['estimator'][0])\n",
    "svc_clfs.append(svc_cv_results[1]['estimator'][0])\n",
    "svc_clfs.append(svc_cv_results[2]['estimator'][0])\n",
    "svc_clfs.append(svc_cv_results[3]['estimator'][0])\n",
    "svc_clfs.append(svc_cv_results[4]['estimator'][0])\n",
    "svc_clfs.append(svc_cv_results[5]['estimator'][0])\n",
    "\n",
    "count = 0\n",
    "for classifier in svc_clfs:\n",
    "    with open(\"svc\"+str(count)+\".pickle\",\"wb\") as f:\n",
    "        pickle.dump(classifier,f)\n",
    "    count+=1\n",
    "\",\".join(str(x) for x in lr_get_proba(svc_clfs,test_x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "lr_f = open(\"support_vector_machine.csv\",\"w\")\n",
    "for feat in test_x:\n",
    "    prob = lr_get_proba(svc_clfs,feat)\n",
    "    lr_f.write(str(test.values[k][0]) + \",\" +\",\".join(str(x) for x in prob))\n",
    "    lr_f.write(\"\\n\")\n",
    "    k+=1\n",
    "lr_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when ready, set this to the best model you found, trained on the test data:\n",
    "best_classifier = None\n",
    "\n",
    "with open('classifier.pickle', 'wb') as f: # 'wb' stands for 'write bytes'\n",
    "    pickle.dump(best_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the sample into 70/30, 70% as training and 30% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x,train_y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4591,  485, 2527,  131, 2362,  430])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y_test))\n",
    "np.sum(y_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def average_accuracy(clf):\n",
    "    a = []\n",
    "    c = []\n",
    "    for x in range(len(X_test)):\n",
    "        \n",
    "        pred = clf.predict(X_test[x].reshape(1,-1))\n",
    "        b = [1 if pred[0][y]==y_test[x][y] else 0 for y in range(6)]\n",
    "        c.append(accuracy_score(y_test[x],pred[0]))\n",
    "        \n",
    "        a.append(b)\n",
    "    print(np.mean(c))\n",
    "    return [k/len(y_test) for k in np.sum(a,axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050593248663101\n",
      "0.9720992090017826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9280790441176471,\n",
       " 0.9898688168449198,\n",
       " 0.9655539772727273,\n",
       " 0.9972635360962567,\n",
       " 0.9608121657754011,\n",
       " 0.9910177139037433]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "print(accuracy_score(y_test,tree.predict(X_test)))\n",
    "average_accuracy(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9422418114973262,\n",
       " 0.9898688168449198,\n",
       " 0.9733873663101604,\n",
       " 0.9972635360962567,\n",
       " 0.9635904077540107,\n",
       " 0.9911639371657754]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=4)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "average_accuracy(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9086522393048129\n",
      "0.9050593248663101\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_test,y_test))\n",
    "print(tree.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_average_accuracy(clf,i):\n",
    "    a = []\n",
    "    c = []\n",
    "    for x in range(len(X_test)):\n",
    "        \n",
    "        pred = clf.predict(X_test[x].reshape(1,-1))\n",
    "        \n",
    "        b = [1 if pred[0]==y_test[x][i] else 0 ]\n",
    "        \n",
    "        \n",
    "        a.append(b)\n",
    "    \n",
    "    return [k/len(y_test) for k in np.sum(a,axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = []\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,0)))\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,1)))\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,2)))\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,3)))\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,4)))\n",
    "lr.append(LogisticRegression().fit(X_train,column(y_train,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9323404077540107], [0.9886363636363636], [0.965386864973262], [0.9972217580213903], [0.9596632687165776], [0.9907670454545454]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_performance= [lr_average_accuracy(lr[x],x) for x in range(6)]\n",
    "print(lr_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928747493315508\n",
      "[[0.928747493315508], [0.9898688168449198], [0.9643841911764706], [0.9972635360962567], [0.9582637032085561], [0.9910177139037433]]\n"
     ]
    }
   ],
   "source": [
    "svc = []\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,0)))\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,1)))\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,2)))\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,3)))\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,4)))\n",
    "svc.append(svm.SVC(probability=False).fit(X_train,column(y_train,5)))\n",
    "\n",
    "print(svc[0].score(X_test,column(y_test,0)))\n",
    "\n",
    "svc_performance= [lr_average_accuracy(svc[x],x) for x in range(6)]\n",
    "print(svc_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09590157085561497, 0.010131183155080214, 0.05278659759358289, 0.0027364639037433156, 0.0493399064171123, 0.008982286096256684]\n"
     ]
    }
   ],
   "source": [
    "sample_percentage= [x/len(y_test) for x in np.sum(y_test,axis=0)]\n",
    "print(sample_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111699\n",
      "[10703  1110  5922   347  5515   975]\n",
      "[0.09582001629378956, 0.009937421104933796, 0.05301748448956571, 0.0031065631742450694, 0.04937376341775665, 0.00872881583541482]\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(np.sum(y_train,axis=0))\n",
    "train_sample_percentage= [x/len(y_train) for x in np.sum(y_train,axis=0)]\n",
    "print(train_sample_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92.8747493315508,\n",
       " 98.98688168449198,\n",
       " 96.43841911764706,\n",
       " 99.72635360962568,\n",
       " 95.82637032085562,\n",
       " 99.10177139037432]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [0.9422418114973262,\n",
    " 0.9898688168449198,\n",
    " 0.9733873663101604,\n",
    " 0.9972635360962567,\n",
    " 0.9635904077540107,\n",
    " 0.9911639371657754]\n",
    "[x[0]*100 for x in svc_performance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
